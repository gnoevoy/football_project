WEB SCRAPING 
- extract links from catalog
- extrat data from links -> write to raw files
- transform data -> write to clean files
- load files to db's

BIGQUERY
- extract data from API -> store raw files
- transform row files -> write to clean files
- upload to bigquery

>> run inside docker container
>> retrieve logs from docker container
>> optmize code: error handling, paths, parallel execution

=======================================================================


REST API
- structure data in json format